import os
import streamlit as st
from openai import OpenAI
from src.pdf_utils import read_pdf_text

st.title("ğŸ’¬ Chatbot (OpenAI)")
st.caption("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸç ”ä¿®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å…ƒã«ã€AIã¨å¯¾è©±ã—ãªãŒã‚‰ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚")

# ===== PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ =====
uploaded_pdf = st.file_uploader("ç ”ä¿®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆPDFï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"])

if "doc_text" not in st.session_state:
    st.session_state.doc_text = ""
if "doc_pages" not in st.session_state:
    st.session_state.doc_pages = 0

if uploaded_pdf is not None:
    pdf_bytes = uploaded_pdf.read()
    text, pages = read_pdf_text(pdf_bytes)
    st.session_state.doc_text = text
    st.session_state.doc_pages = pages
    st.success(f"ğŸ“„ PDFã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼š{pages}ãƒšãƒ¼ã‚¸")
else:
    st.info("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨å†…å®¹ã‚’è§£æã§ãã¾ã™ã€‚")

# ===== APIã‚­ãƒ¼ï¼ˆSecrets / ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•å–å¾—ï¼‰=====
api_key = (st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY") or "").strip()
project_id = (st.secrets.get("OPENAI_PROJECT_ID") or os.getenv("OPENAI_PROJECT_ID") or "").strip()
if not api_key:
    st.error("OpenAIã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Secretsã« OPENAI_API_KEY ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

client_args = {"api_key": api_key}
if project_id:
    client_args["project"] = project_id
client = OpenAI(**client_args)

# ===== ãƒãƒ£ãƒƒãƒˆå±¥æ­´ =====
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": (
                "ğŸ’¬ ç ”ä¿®ãŠç–²ã‚Œã•ã¾ã§ã—ãŸï¼\n"
                "ã¾ãšã¯ç ”ä¿®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆPDFï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n"
                "ã‚¢ãƒƒãƒ—ã§ããŸã‚‰ **ok** ã¨ã ã‘é€ã£ã¦ãã ã•ã„ã€‚"
            ),
        }
    ]

# ===== æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º =====
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# ===== å…¥åŠ›ã¨å¿œç­” =====
MODEL = "gpt-4o-mini"

context_snippet = st.session_state.doc_text[:6000] if st.session_state.doc_text else ""
system_prompt = (
    "ã‚ãªãŸã¯ã€ç ”ä¿®ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚’æ”¯æ´ã™ã‚‹å°‚é–€å®¶ã€ã§ã™ã€‚"
    "ä¸å¯§ã§è«–ç†çš„ã«ã€æ–‡è„ˆã«æ²¿ã£ã¦åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    + (f"\n\n--- å‚è€ƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŠœç²‹ ---\n{context_snippet}" if context_snippet else "")
)

if prompt := st.chat_input("ç ”ä¿®ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆã‚’ã¯ã˜ã‚ã¾ã—ã‚‡ã†ï¼ˆã“ã“ã«è©±ã—ã‹ã‘ã¦ãã ã•ã„ï¼‰"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ===== ã€Œokã€ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° =====
    normalized = prompt.strip().lower()
    if normalized in {"ok", "ï½ï½‹", "ãŠk", "äº†è§£", "ã‚¢ãƒƒãƒ—ã—ãŸ", "upã—ãŸ", "done", "å®Œäº†"}:
        if st.session_state.doc_text:
            next_msg = (
                "ç ”ä¿®ã‚’å—ã‘ã¦ã©ã†ã§ã—ãŸã‹ï¼Ÿ\n"
                "ã¾ãšã¯**æ„Ÿæƒ³ã‚’æ°—è»½ã«æ›¸ã„ã¦ãã ã•ã„ğŸ˜‰**"
            )
        else:
            next_msg = (
                "ã¾ã PDFãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„ã‚ˆã†ã§ã™ã€‚\n"
                "å…ˆã«ç ”ä¿®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆPDFï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
            )

        with st.chat_message("assistant"):
            st.markdown(next_msg)
        st.session_state.messages.append({"role": "assistant", "content": next_msg})
        st.stop()

    # ===== é€šå¸¸ã®å¿œç­” =====
    messages_for_api = [{"role": "system", "content": system_prompt}]
    messages_for_api += st.session_state.messages

    stream = client.chat.completions.create(
        model=MODEL,
        messages=messages_for_api,
        stream=True,
    )

    with st.chat_message("assistant"):
        assistant_text = st.write_stream(stream)

    st.session_state.messages.append({"role": "assistant", "content": assistant_text})
